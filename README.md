Image Caption Generator Using Deep Learning

This project involved developing an Image Caption Generator using deep learning techniques on the Flickr8k dataset, combining computer vision and natural language processing. High-level image features were extracted using a pre-trained ResNet50 CNN model and integrated with a sequence-generating LSTM network for caption prediction. Comprehensive text preprocessing was applied using NLTK, including tokenization, stopword removal, padding, and embedding layers to prepare textual descriptions for training. An encoder-decoder architecture was designed and trained to generate contextually accurate and human-like captions for unseen images, effectively demonstrating the fusion of vision and language models. The project leveraged Python, Keras, TensorFlow, ResNet50, LSTM, NLTK, NumPy, Pandas, and Matplotlib.
